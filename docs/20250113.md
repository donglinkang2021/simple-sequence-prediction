# 20250113

After reviewing SSM models today, I realized that my experiments were incomplete.

1. Plan to train and evaluate prediction capabilities of different models on the `4single` dataset
2. Plan to conduct hyperparameter tuning on input sequence length to achieve better performance on the `4single` dataset, which contains two peaks or longer sequence patterns

Training scripts:

```bash
# baseline model
python train.py --multirun \
    model=lstm \
    dataset=y_w,4single \
    train.learning_rate=3e-3,1e-3,5e-4,3e-4,1e-4

# our model
python train.py --multirun \
    train.is_align_target=True \
    model=att,vq,att_mh,vq_mh \
    dataset=y_w,4single \
    train.learning_rate=3e-3,1e-3,5e-4,3e-4,1e-4
```

Below are the training and prediction results on the `y_w` dataset. Most attention models outperform LSTM:

| Model                                                                                                     |   Predict/mse_regressive |   Predict/mse_batch |   Final/train_loss |   Final/val_loss |
|-----------------------------------------------------------------------------------------------------------|--------------------------|---------------------|--------------------|------------------|
| [att-64-1-1-512-is_inln-is_qln-is_kln-is_causal-sinpe](./logs/att_y_w_ts112_lr0.0005/2025-01-13-21-54-29) |                  1123.62 |             1128.09 |          0.0194332 |        0.0170119 |
| [att_mh-64-8-1-1-1-512-is_kln-is_causal-sinpe](./logs/att_mh_y_w_ts112_lr0.0005/2025-01-13-21-56-43)      |                  1127.6  |             1098.34 |          0.0184686 |        0.0165926 |
| [att_mh-64-8-1-1-1-512-is_kln-is_causal-sinpe](./logs/att_mh_y_w_ts112_lr0.003/2025-01-13-21-56-32)       |                  1277.27 |             1097.75 |          0.0162212 |        0.0154003 |
| [att_mh-64-8-1-1-1-512-is_kln-is_causal-sinpe](./logs/att_mh_y_w_ts112_lr0.001/2025-01-13-21-56-37)       |                  1407.15 |             1127.35 |          0.017035  |        0.0161574 |
| [lstm-1-64-2-1](./logs/lstm_y_w_ts112_lr0.0003/2025-01-13-21-53-09)                                       |                  1496.39 |             1098.17 |          0.015541  |        0.0135345 |
| [lstm-1-64-2-1](./logs/lstm_y_w_ts112_lr0.0005/2025-01-13-21-53-04)                                       |                  1568.19 |             1115.62 |          0.015774  |        0.013831  |
| [att-64-1-1-512-is_inln-is_qln-is_kln-is_causal-sinpe](./logs/att_y_w_ts112_lr0.0003/2025-01-13-21-54-34) |                  1863.04 |             1156.63 |          0.021759  |        0.0177139 |
| [att_mh-64-8-1-1-1-512-is_kln-is_causal-sinpe](./logs/att_mh_y_w_ts112_lr0.0001/2025-01-13-21-56-53)      |                  1954.19 |             1211.73 |          0.0201788 |        0.0182053 |
| [att-64-1-1-512-is_inln-is_qln-is_kln-is_causal-sinpe](./logs/att_y_w_ts112_lr0.001/2025-01-13-21-54-25)  |                  1998.94 |             1123.66 |          0.0176142 |        0.0160157 |
| [lstm-1-64-2-1](./logs/lstm_y_w_ts112_lr0.001/2025-01-13-21-52-59)                                        |                  2384.63 |             1126.47 |          0.0159418 |        0.0140268 |

The following models are trained and tested on the `4single` dataset. Most models show poor prediction performance. Next, we'll optimize the hyperparameters, mainly focusing on time-step adjustments.

| Model                                                                                                    |   Predict/mse_regressive |   Predict/mse_batch |   Final/train_loss |   Final/val_loss |
|----------------------------------------------------------------------------------------------------------|--------------------------|---------------------|--------------------|------------------|
| [vq-64-64-1-1-512-is_causal-randpe](./logs/vq_4single_ts112_lr0.0001/2025-01-13-21-56-24)                |                  20751.3 |             2722.98 |          0.176583  |        0.172754  |
| [vq_mh-64-64-8-4-1-1-512-is_inln-is_n_pe-rope](./logs/vq_mh_4single_ts112_lr0.0005/2025-01-13-21-58-41)  |                  24268.4 |             2113.12 |          0.0811675 |        0.0828622 |
| [vq_mh-64-64-8-4-1-1-512-is_inln-is_n_pe-rope](./logs/vq_mh_4single_ts112_lr0.001/2025-01-13-21-58-29)   |                  24649.5 |             1977.2  |          0.0796967 |        0.0814837 |
| [vq_mh-64-64-8-4-1-1-512-is_inln-is_n_pe-rope](./logs/vq_mh_4single_ts112_lr0.003/2025-01-13-21-58-19)   |                  25301.4 |             1942.9  |          0.0795776 |        0.0813123 |
| [vq-64-64-1-1-512-is_causal-randpe](./logs/vq_4single_ts112_lr0.0003/2025-01-13-21-56-16)                |                  27897.9 |             2010.93 |          0.111192  |        0.108716  |
| [att_mh-64-8-1-1-1-512-is_kln-is_causal-sinpe](./logs/att_mh_4single_ts112_lr0.0003/2025-01-13-21-57-31) |                  28387.1 |             1309.87 |          0.05514   |        0.0562654 |
| [vq-64-64-1-1-512-is_causal-randpe](./logs/vq_4single_ts112_lr0.003/2025-01-13-21-55-53)                 |                  29481   |             1991.11 |          0.0948976 |        0.0946722 |
| [vq-64-64-1-1-512-is_causal-randpe](./logs/vq_4single_ts112_lr0.0005/2025-01-13-21-56-08)                |                  29551.5 |             2008.6  |          0.103821  |        0.10218   |
| [vq-64-64-1-1-512-is_causal-randpe](./logs/vq_4single_ts112_lr0.001/2025-01-13-21-56-01)                 |                  29758.8 |             2009.97 |          0.0984412 |        0.0970267 |
| [lstm-1-64-2-1](./logs/lstm_4single_ts112_lr0.0005/2025-01-13-21-53-37)                                  |                  31854.4 |             1360.52 |          0.0557469 |        0.066151  |

```bash
# baseline model
python train.py --multirun \
    model=lstm \
    dataset=4single \
    train.learning_rate=3e-3,1e-3,5e-4,3e-4,1e-4 \
    train.time_steps=64,128,256,512,1024

# our model
python train.py --multirun \
    train.is_align_target=True \
    model=att,vq,att_mh,vq_mh \
    dataset=4single \
    train.learning_rate=3e-3,1e-3,5e-4,3e-4,1e-4 \
    train.time_steps=64,128,256,512,1024
```